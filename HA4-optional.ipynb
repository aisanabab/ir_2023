{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c087b2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk, parallel_bulk\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import numpy as np\n",
    "import ir_measures\n",
    "from ir_measures import *\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216ece00",
   "metadata": {},
   "source": [
    "## Collection indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e0081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wikIR/documents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682f314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ee2ba00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Without stemming\n",
    "\n",
    "mappings = {\n",
    "    'properties': {\n",
    "        '_document': {\n",
    "            'type': 'text',\n",
    "            'analyzer': 'standard'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "settings_w = {\n",
    "    'analysis' : {\n",
    "        'analyzer' : 'standard' \n",
    "        \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def create_es_action(index, doc_id, document):\n",
    "    return {\n",
    "        '_index': index,\n",
    "        '_id': doc_id,\n",
    "        '_document': document\n",
    "    }\n",
    "\n",
    "\n",
    "def es_action_generator():\n",
    "    for doc_id, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "        doc =  row['text_right']\n",
    "        yield create_es_action(index_name, row['id_right'], doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75ba04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name='wiki2'\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "es.indices.create(index=index_name, settings=settings, mappings=mappings)\n",
    "\n",
    "start = time()\n",
    "for ok, result in parallel_bulk(es, es_action_generator(), queue_size=4, thread_count=4, chunk_size=1000):\n",
    "    if not ok:\n",
    "        print(result)\n",
    "stop = time()\n",
    "\n",
    "print('Indexing time:', stop-start)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6761d023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_result(search_result):\n",
    "    res = search_result['hits']\n",
    "    results = {}\n",
    "    for hit in res['hits']:\n",
    "        results[hit[\"_id\"]] = hit[\"_score\"]\n",
    "    return results\n",
    "        \n",
    "    \n",
    "def search(query, i):\n",
    "    s = pretty_print_result(es.search(index=i, query=query, size=50))\n",
    "    return s\n",
    "\n",
    "\n",
    "def query(l):\n",
    "    pop = {\n",
    "        'bool': {\n",
    "            'must': {\n",
    "                    'match': {\n",
    "                        '_document': l\n",
    "                    }\n",
    "            },\n",
    "                'should': {\n",
    "                    'match_phrase': {\n",
    "                        '_document': {\n",
    "                            \"query\": l,\n",
    "                            \"boost\": 2,\n",
    "                            'slop': 10\n",
    "                        }                           \n",
    "                    }                    \n",
    "                },\n",
    "            \"minimum_should_match\": 1\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    return pop\n",
    "\n",
    "\n",
    "def querysearch(queries, indexname):\n",
    "    results ={}\n",
    "    for q in range(len(queries['text_left'])):\n",
    "        row = queries['text_left'][q]\n",
    "        qu = query(row)\n",
    "        res = search(qu, indexname)\n",
    "        results[str(queries['id_left'][q])] = res\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab0d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfq_tr = pd.read_csv('wikIR/training/queries.csv')\n",
    "dfq_t = pd.read_csv('wikIR/test/queries.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9550b4dd",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35738630",
   "metadata": {},
   "source": [
    "#### Sampling and retrieving using Elasticsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1d0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_s = dfq_tr.sample(n=200).sort_values(by=['id_left']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b67dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = querysearch(tr_s, 'wiki2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e314e00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min-max normalise BM25\n",
    "scores = []\n",
    "for qdp in runs:\n",
    "    if len(runs[str(qdp)]) != 0:\n",
    "        for doc in runs[str(qdp)]:\n",
    "            scores.append(runs[str(qdp)][str(doc)])\n",
    "            \n",
    "max_score = np.max(scores)\n",
    "min_score = np.min(scores)\n",
    "scores = (scores - min_score)/(max_score - min_score)\n",
    "\n",
    "i = 0\n",
    "for qdp in runs:\n",
    "    if len(runs[str(qdp)]) != 0:\n",
    "        for doc in runs[str(qdp)]:\n",
    "            runs[str(qdp)][str(doc)] = scores[i]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76bfe11",
   "metadata": {},
   "source": [
    "#### Cosine similarities for query/document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fa000ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L6-cos-v5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79a78c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [14:44<00:00,  4.42s/it]\n"
     ]
    }
   ],
   "source": [
    "cosine = {}\n",
    "for qdp in tqdm(runs):\n",
    "    qp_cosine = {}\n",
    "    if len(runs[str(qdp)]) != 0:\n",
    "        query = tr_s['text_left'][np.where(tr_s['id_left'] == int(qdp))[0][0]]\n",
    "        docs = [df['text_right'][np.where(df['id_right'] == int(doc))[0][0]] for doc in runs[str(qdp)]]\n",
    "        query_emb = model.encode(query)\n",
    "        doc_emb = model.encode(docs)\n",
    "        dot_scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "        i = 0\n",
    "        for doc in runs[str(qdp)]:\n",
    "            qp_cosine[str(doc)] = dot_scores[i]\n",
    "            i += 1\n",
    "    cosine[str(qdp)] = qp_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceba256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min-max normalise\n",
    "scores_cos = []\n",
    "for qdp in cosine:\n",
    "    if len(cosine[str(qdp)]) != 0:\n",
    "        for doc in cosine[str(qdp)]:\n",
    "            scores_cos.append(cosine[str(qdp)][str(doc)])\n",
    "max_min = [1.0, -1.0]            \n",
    "max_score_cos = np.max(max_min)\n",
    "min_score_cos = np.min(max_min)\n",
    "scores_cos = (scores_cos - min_score_cos)/(max_score_cos - min_score_cos)\n",
    "\n",
    "i = 0\n",
    "for qdp in cosine:\n",
    "    if len(cosine[str(qdp)]) != 0:\n",
    "        for doc in cosine[str(qdp)]:\n",
    "            cosine[str(qdp)][str(doc)] = scores_cos[i]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdef0ac",
   "metadata": {},
   "source": [
    "##### Just evaluating two rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b52103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbm_tr = pd.read_table('wikIR/training/qrels', header = None, names = ['id_left', 'n_u', 'id_right', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "836d599a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_tr = {}\n",
    "for q_id in dfbm_tr['id_left'].unique():\n",
    "    did = {}\n",
    "    for d_id in dfbm_tr['id_right'][np.where(dfbm_tr['id_left'] == q_id)[0]]:\n",
    "        did[str(d_id)] = int(dfbm_tr['label'][np.where((dfbm_tr['id_left'] == q_id)&(dfbm_tr['id_right']==d_id))[0][0]]) \n",
    "    qrels_tr[str(q_id)] = did\n",
    "#maybe I was just supposed to use their built-in function, but I have written that code, so I didn't change it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0dc5e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(tr_s['id_left'])\n",
    "collection = ['Retrieved', 'Cosine similarity']\n",
    "run = [runs, cosine]\n",
    "measures = [(AP(rel=1)@20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a9be050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for collection Retrieved {AP@20: 0.018747767843860168}\n",
      "Results for collection Cosine similarity {AP@20: 0.021426151583429306}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(run)):\n",
    "    print(\"Results for collection\", collection[i], ir_measures.calc_aggregate(measures, qrels_tr, run[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0b2e39",
   "metadata": {},
   "source": [
    "#### Finding alpha that maximizes MAP@20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c63137e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1001/1001 [00:38<00:00, 26.17it/s]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(0, 1.001, 0.001)\n",
    "max_val = 0\n",
    "best_alpha = 0\n",
    "runs_copy = runs\n",
    "cosine_copy = cosine\n",
    "for alpha in tqdm(a): \n",
    "    candidate = {}\n",
    "    for qdp in runs:\n",
    "        candidate[str(qdp)] = {}\n",
    "        if len(runs[str(qdp)]) != 0:\n",
    "            for doc in runs[str(qdp)]:\n",
    "                candidate[str(qdp)][str(doc)] = alpha * runs[str(qdp)][str(doc)] + (1 - alpha) * cosine[str(qdp)][str(doc)]\n",
    "    score = ir_measures.calc_aggregate([(MAP(rel=1)@20)], qrels_tr, candidate)[AP@20]\n",
    "    if score > max_val:\n",
    "        max_val = score\n",
    "        best_alpha = alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "69e57967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha that maximizes MAP@20 on train data:  0.261\n"
     ]
    }
   ],
   "source": [
    "print('Alpha that maximizes MAP@20 on train data: ', best_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d006202",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e931bfa2",
   "metadata": {},
   "source": [
    "BM25 scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a4e9cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_BM25 = querysearch(dfq_t, 'wiki2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a394cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min-max normalise BM25\n",
    "test_scores = []\n",
    "for qdp in test_BM25:\n",
    "    if len(test_BM25[str(qdp)]) != 0:\n",
    "        for doc in test_BM25[str(qdp)]:\n",
    "            test_scores.append(test_BM25[str(qdp)][str(doc)])\n",
    "            \n",
    "test_max_score = np.max(test_scores)\n",
    "test_min_score = np.min(test_scores)\n",
    "test_scores = (test_scores - test_min_score)/(test_max_score - test_min_score)\n",
    "\n",
    "i = 0\n",
    "for qdp in test_BM25:\n",
    "    if len(test_BM25[str(qdp)]) != 0:\n",
    "        for doc in test_BM25[str(qdp)]:\n",
    "            test_BM25[str(qdp)][str(doc)] = test_scores[i]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217af28",
   "metadata": {},
   "source": [
    "Cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ebffb411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [06:20<00:00,  3.81s/it]\n"
     ]
    }
   ],
   "source": [
    "test_cosine = {}\n",
    "for qdp in tqdm(test_BM25):\n",
    "    qp_cosine = {}\n",
    "    if len(test_BM25[str(qdp)]) != 0:\n",
    "        query = dfq_t['text_left'][np.where(dfq_t['id_left'] == int(qdp))[0][0]]\n",
    "        docs = [df['text_right'][np.where(df['id_right'] == int(doc))[0][0]] for doc in test_BM25[str(qdp)]]\n",
    "        query_emb = model.encode(query)\n",
    "        doc_emb = model.encode(docs)\n",
    "        dot_scores = util.dot_score(query_emb, doc_emb)[0].cpu().tolist()\n",
    "        i = 0\n",
    "        for doc in test_BM25[str(qdp)]:\n",
    "            qp_cosine[str(doc)] = dot_scores[i]\n",
    "            i += 1\n",
    "    test_cosine[str(qdp)] = qp_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2103b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Min-max normalise\n",
    "test_scores_cos = []\n",
    "for qdp in test_cosine:\n",
    "    if len(test_cosine[str(qdp)]) != 0:\n",
    "        for doc in test_cosine[str(qdp)]:\n",
    "            test_scores_cos.append(test_cosine[str(qdp)][str(doc)])\n",
    "max_min = [1.0, -1.0]            \n",
    "max_score_cos = np.max(max_min)\n",
    "min_score_cos = np.min(max_min)\n",
    "test_scores_cos = (test_scores_cos - min_score_cos)/(max_score_cos - min_score_cos)\n",
    "\n",
    "i = 0\n",
    "for qdp in test_cosine:\n",
    "    if len(test_cosine[str(qdp)]) != 0:\n",
    "        for doc in test_cosine[str(qdp)]:\n",
    "            test_cosine[str(qdp)][str(doc)] = test_scores_cos[i]\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fbccf8",
   "metadata": {},
   "source": [
    "New ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6b48c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = {}\n",
    "for qdp in test_BM25:\n",
    "    new[str(qdp)] = {}\n",
    "    if len(test_BM25[str(qdp)]) != 0:\n",
    "        for doc in test_BM25[str(qdp)]:\n",
    "            new[str(qdp)][str(doc)] = best_alpha * test_BM25[str(qdp)][str(doc)] + (1 - best_alpha) * test_cosine[str(qdp)][str(doc)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8770c7c",
   "metadata": {},
   "source": [
    "Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e71ecdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbm_t = pd.read_table('wikIR/test/qrels', header = None, names = ['id_left', 'n_u', 'id_right', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fe0f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_t = {}\n",
    "for q_id in dfbm_t['id_left'].unique():\n",
    "    did = {}\n",
    "    for d_id in dfbm_t['id_right'][np.where(dfbm_t['id_left'] == q_id)[0]]:\n",
    "        did[str(d_id)] = int(dfbm_t['label'][np.where((dfbm_t['id_left'] == q_id)&(dfbm_t['id_right']==d_id))[0][0]]) \n",
    "    qrels_t[str(q_id)] = did\n",
    "#maybe I was just supposed to use their built-in function, but I have written that code, so I didn't change it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3fadd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame(dfq_t['id_left'])\n",
    "test_collection = ['Retrieved', 'Cosine similarity', 'New ranking']\n",
    "test_run = [test_BM25, test_cosine, new]\n",
    "test_measures = [(P(rel=1)@10),(P(rel=1)@20),(AP(rel=1)@20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef9f6182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for collection Retrieved {AP@20: 0.11117170166130358, P@20: 0.11549999999999999, P@10: 0.17899999999999994}\n",
      "Results for collection Cosine similarity {AP@20: 0.13082231663095173, P@20: 0.11999999999999998, P@10: 0.18299999999999997}\n",
      "Results for collection New ranking {AP@20: 0.13357284517315268, P@20: 0.12349999999999998, P@10: 0.1839999999999999}\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_run)):\n",
    "    print(\"Results for collection\", test_collection[i], ir_measures.calc_aggregate(test_measures, qrels_t, test_run[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
